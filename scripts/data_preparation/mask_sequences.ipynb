{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the compressed CSV files for each partition into dfs\n",
    "data_partition_1 = pd.read_csv(\"../../data/data_model/datasets/data_partition_1.csv.gz\", \n",
    "                                   dtype={'annotation_source': 'str'},\n",
    "                                   compression='gzip')\n",
    "data_partition_2 = pd.read_csv(\"../../data/data_model/datasets/data_partition_2.csv.gz\",\n",
    "                                   dtype={'annotation_source': 'str'},\n",
    "                                   compression='gzip')\n",
    "data_partition_3 = pd.read_csv(\"../../data/data_model/datasets/data_partition_3.csv.gz\", \n",
    "                                   dtype={'annotation_source': 'str'},\n",
    "                                   compression='gzip')\n",
    "data_partition_4 = pd.read_csv(\"../../data/data_model/datasets/data_partition_4.csv.gz\", \n",
    "                                   dtype={'annotation_source': 'str'},\n",
    "                                   compression='gzip')\n",
    "data_partition_5 = pd.read_csv(\"../../data/data_model/datasets/data_partition_5.csv.gz\", \n",
    "                                   dtype={'annotation_source': 'str'},\n",
    "                                   compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of all species\n",
    "species_list = ['Saccharomyces cerevisiae', 'Ustilago maydis', 'Schizosaccharomyces pombe', 'Aspergillus nidulans', 'Cryptococcus neoformans', 'Neurospora crassa', 'Coprinopsis cinerea', 'Rhizophagus irregularis', 'Schizophyllum commune',\n",
    "                'Plasmodium falciparum', 'Entamoeba histolytica', 'Dictyostelium discoideum', 'Giardia intestinalis', 'Trypanosoma brucei', 'Leishmania donovani', 'Toxoplasma gondii', 'Eimeria maxima', 'Oryza sativa', 'Arabidopsis thaliana', \n",
    "                'Selaginella moellendorffii', 'Brachypodium distachyon', 'Setaria viridis', 'Zea mays', 'Hordeum vulgare', 'Triticum aestivum', 'Phoenix dactylifera', 'Lotus japonicus', 'Medicago truncatula', 'Nicotiana tabacum', 'Glycine max', \n",
    "                'Solanum lycopersicum', 'Trichoplax adhaerens', 'Tribolium castaneum', 'Manduca sexta', 'Apis mellifera', 'Strongylocentrotus purpuratus', 'Daphnia carinata', 'Drosophila melanogaster', 'Anopheles gambiae', 'Caenorhabditis elegans', \n",
    "                'Gallus gallus', 'Alligator mississippiensis', 'Xenopus laevis', 'Oreochromis niloticus', 'Homo sapiens', 'Bos taurus', 'Mus musculus',  'Ovis aries', 'Canis lupus familiaris', 'Equus caballus', 'Gorilla gorilla', 'Pan troglodytes', \n",
    "                'Rattus norvegicus', 'Oryctolagus cuniculus', 'Sus scrofa', 'Danio rerio', 'Oryzias latipes', 'Taeniopygia guttata', 'Columba livia', 'Anolis carolinensis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_sequence(row, reference_df):\n",
    "    \"\"\"\n",
    "    Extends the sequence in the given row by finding the matching sequence in the reference dataframe and appending 100 downstream nucleotides.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the data_partition_masked dataframe containing the sequence to be extended.\n",
    "        reference_df (pd.DataFrame): The reference dataframe containing the full sequences to find the downstream nucleotides.\n",
    "\n",
    "    Returns:\n",
    "        result (str): The extended sequence with 100 downstream nucleotides appended if a match is found, otherwise the original sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the matching row in reference_df using the seq_number/Seq_number mapping\n",
    "    match = reference_df[reference_df['Seq_number'] == row['seq_number']]\n",
    "    \n",
    "    if not match.empty:\n",
    "        # Get the data_partition_masked sequence and reference_df sequence\n",
    "        data_partition_masked_sequence = row['Sequence']\n",
    "        reference_sequence = match.iloc[0]['Sequence']\n",
    "        \n",
    "        # Find the overlap position\n",
    "        overlap_pos = reference_sequence.find(data_partition_masked_sequence)\n",
    "        if overlap_pos != -1:\n",
    "            # Extract 100 downstream nucleotides\n",
    "            downstream_start = overlap_pos + len(data_partition_masked_sequence)\n",
    "            downstream_end = downstream_start + 100\n",
    "            downstream_seq = reference_sequence[downstream_start:downstream_end]\n",
    "            \n",
    "            result = data_partition_masked_sequence + downstream_seq\n",
    "            \n",
    "            # Assertion: Ensure the returned value is a string and includes the original sequence\n",
    "            assert isinstance(result, str), \"Output is not a string.\"\n",
    "            assert data_partition_masked_sequence in result, \"Original sequence not present in the output.\"\n",
    "            assert len(result) >= len(data_partition_masked_sequence), \"Output sequence is shorter than expected.\"\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    # Assertion: If no match is found, ensure the original sequence is returned\n",
    "    assert isinstance(row['Sequence'], str), \"Original sequence is not a string.\"\n",
    "    return row['Sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_non_TIS_samples(data_partition, number):\n",
    "    \"\"\" \n",
    "    #Mask upstream seqeunce in non-TIS sequences corresponding to X% in TIS-sequences, with length distributions as in TIS sequences. \n",
    "\n",
    "    Args:\n",
    "        data_partition (pd.DataFrame): The dataframe containing the sequences to be masked.\n",
    "        number (int): The partition number for the data_partition dataframe.\n",
    "    \n",
    "    Output:\n",
    "        data_partition_masked (pd.DataFrame): The dataframe containing the masked sequences.\n",
    "    \"\"\"\n",
    "    data_partition_masked_full = pd.DataFrame()\n",
    "\n",
    "    masked_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for species in species_list:\n",
    "        #print(species)\n",
    "        data_partition_masked = pd.DataFrame()\n",
    "        #Get TIS data, find fraction of sequences with masked nucleotides and distribution of number of masked nucleotides\n",
    "        data_species = data_partition[data_partition[\"Species\"] == species]\n",
    "\n",
    "        TIS_data = data_species[data_species[\"TIS\"] == 1]\n",
    "        TIS_masked_seqs = TIS_data[TIS_data[\"Sequence\"].str.contains(\"N\")]\n",
    "        TIS_masked_seqs_fracs = TIS_masked_seqs.shape[0]/TIS_data.shape[0]\n",
    "        TIS_masked_seqs = TIS_masked_seqs.copy()  # Ensures itâ€™s a new DataFrame\n",
    "        TIS_masked_seqs[\"N_count\"] = TIS_masked_seqs[\"Sequence\"].str.count(\"N\")\n",
    "        N_distribution = TIS_masked_seqs[\"N_count\"].value_counts().sort_index()\n",
    "\n",
    "        total_count += TIS_data.shape[0]\n",
    "        masked_count += TIS_masked_seqs.shape[0]\n",
    "\n",
    "        #Get non-TIS data\n",
    "        non_TIS_data = data_species[data_species[\"TIS\"] == 0]\n",
    "        non_TIS_samples_to_mask = int(len(non_TIS_data) * TIS_masked_seqs_fracs)\n",
    "        non_TIS_sampled_rows = non_TIS_data.sample(n=non_TIS_samples_to_mask, random_state=42).copy()\n",
    "\n",
    "        assert data_species.shape[0] == non_TIS_data.shape[0] + TIS_data.shape[0]\n",
    "\n",
    "        if non_TIS_sampled_rows.shape[0] != 0:\n",
    "            #Draw the number of \"N\"s for each sampled row based on N_distribution\n",
    "            non_TIS_sampled_rows[\"N_count\"] = np.random.choice(\n",
    "                N_distribution.index,  # Possible counts of \"N\"\n",
    "                size=len(non_TIS_sampled_rows),  # Number of samples to draw\n",
    "                p=N_distribution.values / N_distribution.values.sum()  # Probabilities\n",
    "            )\n",
    "\n",
    "            #Modify the sequences\n",
    "            def replace_with_N(sequence, n_count):\n",
    "                return \"N\" * n_count + sequence[n_count:]\n",
    "\n",
    "            non_TIS_sampled_rows[\"Sequence\"] = non_TIS_sampled_rows.apply(\n",
    "                lambda row: replace_with_N(row[\"Sequence\"], row[\"N_count\"]), axis=1\n",
    "            )\n",
    "\n",
    "            # Update non-TIS data with modified sequences\n",
    "            non_TIS_data.update(non_TIS_sampled_rows[[\"Sequence\"]])\n",
    "\n",
    "        data_species_masked = pd.concat([TIS_data, non_TIS_data], axis=0, ignore_index=True)\n",
    "\n",
    "        assert data_species_masked.shape[0] == data_species.shape[0]\n",
    "\n",
    "        data_partition_masked = pd.concat([data_partition_masked, data_species_masked], axis = 0, ignore_index=True)\n",
    "\n",
    "        #Read original datasets\n",
    "        species_formatted = species.lower().replace(\" \", \"_\")\n",
    "        TIS_seqs_df = pd.read_csv(f\"../../data/data_model_preparation/datasets/TIS/mRNA_positive_{species_formatted}.csv.gz\", compression='gzip')\n",
    "        non_TIS_seqs_df1 = pd.read_csv(f\"../../data/data_model_preparation/datasets/non_TIS/mRNA/mRNA_negative_{species_formatted}.csv.gz\", compression='gzip')\n",
    "        non_TIS_seqs_df2 = pd.read_csv(f\"../../data/data_model_preparation/datasets/non_TIS/intergenic/intergenic_data_{species_formatted}.csv.gz\", compression='gzip')\n",
    "        non_TIS_seqs_df3 = pd.read_csv(f\"../../data/data_model_preparation/datasets/non_TIS/introns/introns_{species_formatted}.csv.gz\", compression='gzip')\n",
    "\n",
    "        all_seq_data = pd.concat([TIS_seqs_df, non_TIS_seqs_df1, non_TIS_seqs_df2, non_TIS_seqs_df3], axis = 0, ignore_index=True)\n",
    "\n",
    "        # Apply the function to df1\n",
    "        data_partition_masked['Sequence'] = data_partition_masked.apply(lambda row: extend_sequence(row, all_seq_data), axis=1)\n",
    "        \n",
    "        data_partition_masked_full = pd.concat([data_partition_masked_full, data_partition_masked], axis = 0, ignore_index=True)\n",
    "    \n",
    "    assert data_partition.shape[0] == data_partition_masked_full.shape[0]\n",
    "\n",
    "    print(\"Percentage of non-TIS sequences to be padded: \", round(masked_count / total_count, 4))\n",
    "\n",
    "    #Save the DataFrame as a CSV file compressed with gzip\n",
    "    data_partition_masked.to_csv(f'../../data/data_model/datasets/data_partition_{str(number)}_masked_extended.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58428 232466\n",
      "0.2513\n",
      "58261 232465\n",
      "0.2506\n",
      "58553 232387\n",
      "0.252\n",
      "58339 232416\n",
      "0.251\n",
      "58638 232460\n",
      "0.2522\n"
     ]
    }
   ],
   "source": [
    "mask_non_TIS_samples(data_partition_1, number = 1)\n",
    "mask_non_TIS_samples(data_partition_2, number = 2)\n",
    "mask_non_TIS_samples(data_partition_3, number = 3)\n",
    "mask_non_TIS_samples(data_partition_4, number = 4)\n",
    "mask_non_TIS_samples(data_partition_5, number = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
