{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['alligator_mississippiensis', 'anolis_carolinensis', 'anopheles_gambiae', 'apis_mellifera', 'arabidopsis_thaliana', 'aspergillus_nidulans', 'bos_taurus', 'brachypodium_distachyon', 'caenorhabditis_elegans', 'canis_lupus_familiaris', 'columba_livia', 'coprinopsis_cinerea', 'cryptococcus_neoformans', 'danio_rerio', 'daphnia_carinata', 'dictyostelium_discoideum', 'drosophila_melanogaster', 'eimeria_maxima', 'entamoeba_histolytica', 'equus_caballus', 'gallus_gallus', 'giardia_intestinalis', 'glycine_max', 'gorilla_gorilla', 'homo_sapiens', 'hordeum_vulgare', 'leishmania_donovani', 'lotus_japonicus', 'manduca_sexta', 'medicago_truncatula', 'mus_musculus', 'neurospora_crassa', 'nicotiana_tabacum', 'oreochromis_niloticus', 'oryctolagus_cuniculus', 'oryza_sativa', 'oryzias_latipes', 'ovis_aries', 'pan_troglodytes', 'phoenix_dactylifera', 'plasmodium_falciparum', 'rattus_norvegicus', 'rhizophagus_irregularis', 'saccharomyces_cerevisiae', 'schizophyllum_commune', 'schizosaccharomyces_pombe', 'selaginella_moellendorffii', 'setaria_viridis', 'solanum_lycopersicum', 'strongylocentrotus_purpuratus', 'sus_scrofa', 'taeniopygia_guttata', 'toxoplasma_gondii', 'tribolium_castaneum', 'trichoplax_adhaerens', 'triticum_aestivum', 'trypanosoma_brucei', 'ustilago_maydis', 'xenopus_laevis', 'zea_mays']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces predictions for transcript-level benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIS Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dict_full_transcripts():\n",
    "    information_dict = dict()\n",
    "    information_dict[\"species\"] = []\n",
    "    information_dict[\"seq_number\"] = []\n",
    "    information_dict[\"label\"] = []\n",
    "    information_dict[\"preds\"] = []\n",
    "\n",
    "    return information_dict\n",
    "\n",
    "TIS_transformer_full_transcripts_preds = init_dict_full_transcripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_atg_positions(species):\n",
    "    species_atgs_dict = {}\n",
    "    transcript_found = False\n",
    "    startcodons = \"ATG\"\n",
    "\n",
    "    #Get all ATG locations on transcript\n",
    "    with gzip.open(f\"../../data/data_evaluation/input_testsets/mRNA_testsets_processed/input_testset_{species}_softmasked.fasta.gz\", \"rt\") as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                if \"TIS=1\" in line:\n",
    "                    transcript_found = True\n",
    "                    TIS_pos = int(line.split(\"ATG_pos=\")[1].split(\"|\")[0])\n",
    "                    seq_number = line.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "            else:\n",
    "                if transcript_found:\n",
    "                    seq = line.strip().upper()\n",
    "                    atg_indices = [i for i in range(len(seq)) if seq.startswith(startcodons, i)]\n",
    "                    atg_indices.remove(TIS_pos)\n",
    "\n",
    "                    #Separate upstream and downstream indices\n",
    "                    upstream_indices = [i for i in atg_indices if i < TIS_pos]\n",
    "                    downstream_indices = [i for i in atg_indices if i > TIS_pos]\n",
    "\n",
    "                    #Check if indices are in the same reading frame as the TIS\n",
    "                    same_frame = lambda x: (x - TIS_pos) % 3 == 0\n",
    "\n",
    "                    #Categorize by frame\n",
    "                    upstream_same_frame = [i for i in upstream_indices if same_frame(i)]\n",
    "                    upstream_diff_frame = [i for i in upstream_indices if not same_frame(i)]\n",
    "                    downstream_same_frame = [i for i in downstream_indices if same_frame(i)]\n",
    "                    downstream_diff_frame = [i for i in downstream_indices if not same_frame(i)]\n",
    "\n",
    "                    #Store results in the dictionary\n",
    "                    species_atgs_dict[seq_number] = {\n",
    "                        \"TIS_pos\": TIS_pos,\n",
    "                        \"upstream_same_frame\": upstream_same_frame,\n",
    "                        \"upstream_diff_frame\": upstream_diff_frame,\n",
    "                        \"downstream_same_frame\": downstream_same_frame,\n",
    "                        \"downstream_diff_frame\": downstream_diff_frame\n",
    "                    }\n",
    "\n",
    "                \n",
    "                transcript_found = False\n",
    "    \n",
    "    return species_atgs_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(species, species_atgs_dict, TIS_transformer_data):\n",
    "    #Load the .npy file with TIS Transformer\n",
    "    tis_transformer_preds_unprocessed = np.load(f'../../data/data_evaluation/TIS_transformer/preds/testset/{species}.npy', allow_pickle=True)\n",
    "\n",
    "    #Run through all sequences predicted upon\n",
    "    for sequence in tis_transformer_preds_unprocessed:\n",
    "        # Extract sequence metadata\n",
    "        sequence_header = sequence[0]\n",
    "        TIS_label = float(sequence_header.split(\"|\")[2].split(\"=\")[1])\n",
    "\n",
    "        if TIS_label == 1.0:\n",
    "            # Extract additional metadata\n",
    "            seq_number = sequence_header.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "            source = sequence_header.split(\"source=\")[1].split(\"|\")[0]\n",
    "            TSS_annotated = sequence_header.split(\"TSS_annotated=\")[1].split(\"|\")[0]\n",
    "\n",
    "            # Get ATG positions and predictions\n",
    "            atg_positions = species_atgs_dict[seq_number]\n",
    "            preds = sequence[1]\n",
    "\n",
    "            TIS_pred = preds[atg_positions[\"TIS_pos\"]]\n",
    "            upstream_same_frame_preds = preds[atg_positions[\"upstream_same_frame\"]]\n",
    "            upstream_diff_frame_preds = preds[atg_positions[\"upstream_diff_frame\"]]\n",
    "            downstream_same_frame_preds = preds[atg_positions[\"downstream_same_frame\"]]\n",
    "            downstream_diff_frame_preds = preds[atg_positions[\"downstream_diff_frame\"]]\n",
    "\n",
    "            # Add predictions and metadata to the final data\n",
    "            TIS_transformer_data.append((TIS_pred, 1.0, \"TIS\", source, TSS_annotated, species, seq_number))\n",
    "            TIS_transformer_data.extend([(pred, 0.0, \"upstream_same_frame\", source, TSS_annotated, species, seq_number) for pred in upstream_same_frame_preds])\n",
    "            TIS_transformer_data.extend([(pred, 0.0, \"upstream_diff_frame\", source, TSS_annotated, species, seq_number) for pred in upstream_diff_frame_preds])\n",
    "            TIS_transformer_data.extend([(pred, 0.0, \"downstream_same_frame\", source, TSS_annotated, species, seq_number) for pred in downstream_same_frame_preds])\n",
    "            TIS_transformer_data.extend([(pred, 0.0, \"downstream_diff_frame\", source, TSS_annotated, species, seq_number) for pred in downstream_diff_frame_preds])\n",
    "\n",
    "\n",
    "    return TIS_transformer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing species: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "TIS_transformer_data = []\n",
    "\n",
    "for species in tqdm(species_list, desc=\"Processing species\"):\n",
    "    species_atgs_dict = extract_atg_positions(species)\n",
    "    TIS_transformer_data = get_preds(species, species_atgs_dict, TIS_transformer_data)\n",
    "\n",
    "TIS_transformer_df_full = pd.DataFrame(TIS_transformer_data, columns=[\"preds\", \"label\", \"ATG_type\", \"annotation_source\", \"TSS_annotated\", \"species\", \"seq_number\"])\n",
    "\n",
    "#save df\n",
    "TIS_transformer_df_full.to_csv('../../data/data_evaluation/preds_processed/transcripts/TIS_transformer_df_transcripts.csv.gz', index=False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetStart 2.0 and ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netstart_preds(preds_subpath):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for species in tqdm(species_list, desc=f\"Processing data in {preds_subpath}\"):\n",
    "        try:\n",
    "            # Read CSV and filter for TIS=1 entries immediately\n",
    "            df = pd.read_csv(f\"../../data/data_evaluation/{preds_subpath}/preds_{species}.csv.gz\", compression = \"gzip\")\n",
    "            df = df[df['entry_line'].str.contains(\"TIS=1\", na=False)]\n",
    "            \n",
    "            # Vectorized operations for extracting values\n",
    "            df['TIS_pos'] = df['entry_line'].str.extract(r'ATG_pos=(\\d+)').astype(int)\n",
    "            df['source'] = df['entry_line'].str.extract(r'source=([^|]+)')\n",
    "            df['seq_number'] = df['entry_line'].str.extract(r'seq_number=([^|]+)')\n",
    "            df['TSS_annotated'] = df['entry_line'].str.extract(r'TSS_annotated=([^|]+)')\n",
    "            \n",
    "            # Vectorized calculations\n",
    "            df['label'] = (df['atg_position'] == df['TIS_pos']).astype(float)\n",
    "            df['TIS_frame'] = df['TIS_pos'] % 3\n",
    "            df['frame'] = df['atg_position'] % 3\n",
    "            df['same_frame'] = df['frame'] == df['TIS_frame']\n",
    "            \n",
    "            # Vectorized ATG_type assignment\n",
    "            conditions = [\n",
    "                df['atg_position'] == df['TIS_pos'],\n",
    "                (df['atg_position'] < df['TIS_pos']) & df['same_frame'],\n",
    "                (df['atg_position'] < df['TIS_pos']) & ~df['same_frame'],\n",
    "                (df['atg_position'] > df['TIS_pos']) & df['same_frame'],\n",
    "                (df['atg_position'] > df['TIS_pos']) & ~df['same_frame']\n",
    "            ]\n",
    "            choices = ['TIS', 'upstream_same_frame', 'upstream_diff_frame', \n",
    "                      'downstream_same_frame', 'downstream_diff_frame']\n",
    "            df['ATG_type'] = np.select(conditions, choices)\n",
    "            \n",
    "            # Create results dictionary\n",
    "            batch_results = df.apply(lambda row: {\n",
    "                \"position\": row['atg_position'],\n",
    "                \"preds\": row['preds'],\n",
    "                \"label\": row['label'],\n",
    "                \"ATG_type\": row['ATG_type'],\n",
    "                \"annotation_source\": row['source'],\n",
    "                \"TSS_annotated\": row['TSS_annotated'],\n",
    "                \"species\": species,\n",
    "                \"seq_number\": row['seq_number']\n",
    "            }, axis=1).tolist()\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data in ablations/netstart1/testset: 100%|██████████| 60/60 [12:40<00:00, 12.68s/it]\n"
     ]
    }
   ],
   "source": [
    "#netstart_overall_df_full = get_netstart_preds(preds_subpath = \"netstart2.0/preds/overall/testset\")\n",
    "#netstart_group_specific_df_full = get_netstart_preds(preds_subpath = \"netstart2.0/preds/group_specific/testset\")\n",
    "#esm2_finetuned_ablation = get_netstart_preds(preds_subpath = \"ablations/esm2_finetuned/testset\")\n",
    "#netstart1_ablation = get_netstart_preds(preds_subpath = \"ablations/netstart1/testset\")\n",
    "\n",
    "#netstart_overall_df_full.to_csv('../../data/data_evaluation/preds_processed/transcripts/netstart_overall_df_transcripts.csv.gz', index=False, compression = \"gzip\")\n",
    "#netstart_group_specific_df_full.to_csv('../../data/data_evaluation/preds_processed/transcripts/netstart_group_specific_df_transcripts.csv.gz', index=False, compression = \"gzip\")\n",
    "#esm2_finetuned_ablation.to_csv('../../data/data_evaluation/preds_processed/transcripts/esm2_finetuned_ablation_df_transcripts.csv.gz', index=False, compression = \"gzip\")\n",
    "#netstart1_ablation.to_csv('../../data/data_evaluation/preds_processed/transcripts/netstart1_ablation_df_transcripts.csv.gz', index=False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces predictions for testset benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dict_testsets():\n",
    "    #Initialize \n",
    "    information_dict = dict()\n",
    "    information_dict[\"species\"] = []\n",
    "    information_dict[\"seq_type\"] = []\n",
    "    information_dict[\"label\"] = []\n",
    "    information_dict[\"preds\"] = []\n",
    "    information_dict[\"annotation_source\"] = []\n",
    "    information_dict[\"seq_number\"] = []\n",
    "    information_dict[\"dataset_type\"] = []\n",
    "    information_dict[\"first_downstream_intron\"] = []\n",
    "    information_dict[\"TSS_annotated\"] = []\n",
    "    information_dict[\"5_flanking_sequence_missing\"] = []\n",
    "    information_dict[\"3_flanking_sequence_missing\"] = []\n",
    "\n",
    "    return information_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIS Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tis_transformer_preds():\n",
    "    #Initialize \n",
    "    TIS_transformer_testset_preds = init_dict_testsets()\n",
    "    TIS_transformer_genomic_preds = init_dict_testsets()\n",
    "\n",
    "\n",
    "    for species in species_list:\n",
    "        #Load the .npy file with TIS Transformer\n",
    "        tis_transformer_preds_unprocessed = np.load(f'../../data/data_evaluation/TIS_transformer/preds/testset/{species}.npy', allow_pickle=True)\n",
    "        \n",
    "        #Run through all sequences predicted upon\n",
    "        for sequence in tis_transformer_preds_unprocessed:\n",
    "            #Get prediction information\n",
    "            sequence_header = sequence[0]\n",
    "            seq_number = sequence_header.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "            TIS_label = float(sequence_header.split(\"TIS=\")[1].split(\"|\")[0])\n",
    "            seq_type = sequence_header.split(\"type=\")[1].split(\"|\")[0]\n",
    "            annotation_source = sequence_header.split(\"source=\")[1].split(\"|\")[0]\n",
    "            TIS_pred_position = int(sequence_header.split(\"ATG_pos=\")[1].split(\"|\")[0])\n",
    "            TSS_annotated = sequence_header.split(\"TSS_annotated=\")[1].strip()\n",
    "\n",
    "            #Extract prediction at labelled position (TIS/non-TIS)\n",
    "            preds = sequence[1]\n",
    "            TIS_pred = preds[TIS_pred_position]\n",
    "\n",
    "            #Write all relevant information to dict\n",
    "            TIS_transformer_testset_preds[\"species\"].append(species)\n",
    "            TIS_transformer_testset_preds[\"seq_type\"].append(seq_type)\n",
    "            TIS_transformer_testset_preds[\"label\"].append(TIS_label)\n",
    "            TIS_transformer_testset_preds[\"preds\"].append(TIS_pred)\n",
    "            TIS_transformer_testset_preds[\"annotation_source\"].append(annotation_source)\n",
    "            TIS_transformer_testset_preds[\"seq_number\"].append(seq_number)\n",
    "            TIS_transformer_testset_preds[\"dataset_type\"].append(\"testset\")\n",
    "            TIS_transformer_testset_preds[\"first_downstream_intron\"].append(None)\n",
    "            TIS_transformer_testset_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "            TIS_transformer_testset_preds[\"5_flanking_sequence_missing\"].append(None)\n",
    "            TIS_transformer_testset_preds[\"3_flanking_sequence_missing\"].append(None)\n",
    "        \n",
    "\n",
    "        #Load genomic testset\n",
    "        tis_transformer_preds_unprocessed_genomic = np.load(f'../../data/data_evaluation/TIS_transformer/preds/genomic/{species}.npy', allow_pickle=True)\n",
    "\n",
    "        #Run through all sequences predicted upon\n",
    "        for sequence in tis_transformer_preds_unprocessed_genomic:\n",
    "            #Get prediction information\n",
    "            sequence_header = sequence[0]\n",
    "            gene_name = sequence_header.split(\"|\")[0]\n",
    "            annotation_source = sequence_header.split(\"source=\")[1].split(\"|\")[0]\n",
    "            TIS_pred_position = int(sequence_header.split(\"TIS_position=\")[1].split(\"|\")[0])\n",
    "            first_downstream_intron = int(sequence_header.split(\"first_downstream_intron_start=\")[1].split(\"|\")[0])\n",
    "            missing_5_flanking_seq = sequence_header.split(\"5_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "            missing_3_flanking_seq = sequence_header.split(\"3_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "            TSS_annotated = sequence_header.split(\"TSS_annotated=\")[1].strip()\n",
    "                \n",
    "            #Extract prediction at labelled position (TIS/non-TIS)\n",
    "            preds = sequence[1]\n",
    "            TIS_pred = preds[TIS_pred_position]\n",
    "                \n",
    "            #Write all relevant information to dict\n",
    "            TIS_transformer_genomic_preds[\"species\"].append(species)\n",
    "            TIS_transformer_genomic_preds[\"seq_type\"].append(\"Genomic TIS\")\n",
    "            TIS_transformer_genomic_preds[\"label\"].append(float(1))\n",
    "            TIS_transformer_genomic_preds[\"preds\"].append(TIS_pred)\n",
    "            TIS_transformer_genomic_preds[\"annotation_source\"].append(annotation_source)\n",
    "            TIS_transformer_genomic_preds[\"seq_number\"].append(gene_name)\n",
    "            TIS_transformer_genomic_preds[\"dataset_type\"].append(\"genomic\")\n",
    "            TIS_transformer_genomic_preds[\"first_downstream_intron\"].append(int(first_downstream_intron))\n",
    "            TIS_transformer_genomic_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "            TIS_transformer_genomic_preds[\"5_flanking_sequence_missing\"].append(missing_5_flanking_seq)\n",
    "            TIS_transformer_genomic_preds[\"3_flanking_sequence_missing\"].append(missing_3_flanking_seq)\n",
    "\n",
    "    TIS_transformer_df = pd.DataFrame(TIS_transformer_testset_preds)\n",
    "    TIS_transformer_genomic_df = pd.DataFrame(TIS_transformer_genomic_preds)\n",
    "\n",
    "    return TIS_transformer_df, TIS_transformer_genomic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUGUSTUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augustus_preds(softmask):\n",
    "    #Initialize\n",
    "    AUGUSTUS_testset_preds = init_dict_testsets()\n",
    "    AUGUSTUS_genomic_preds = init_dict_testsets()\n",
    "\n",
    "    if softmask == True:\n",
    "        dir = \"softmask\"\n",
    "    else:\n",
    "        dir = \"no_softmask\"\n",
    "    #get predictions from all species\n",
    "    for species in species_list:\n",
    "        initiated = False\n",
    "\n",
    "        with open(f'../../data/data_evaluation/AUGUSTUS/preds/{dir}/testset/{species}_preds.gff', \"r\") as file:\n",
    "            for line in file:\n",
    "                #New sequence predicted on\n",
    "                if line.startswith(\"# ----- prediction on sequence number\"):\n",
    "                    \n",
    "                    #If first sequence has been found\n",
    "                    if initiated == True:\n",
    "                        \n",
    "                        #If the matching start codon is found; TIS predicted\n",
    "                        if atg_pos in predicted_atg_pos_list:\n",
    "                            AUGUSTUS_testset_preds[\"preds\"].append(1.0)\n",
    "                        #If the matching start codon is not found; TIS not predicted\n",
    "                        else:\n",
    "                            AUGUSTUS_testset_preds[\"preds\"].append(0.0)\n",
    "\n",
    "                    seq_type = line.split(\"type=\")[1].split(\"|\")[0].replace(\"_\", \" \")\n",
    "                    seq_number = line.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "                    label = line.split(\"TIS=\")[1].split(\"|\")[0]\n",
    "                    source = line.split(\"source=\")[1].split(\"|\")[0] \n",
    "                    TSS_annotated = line.split(\"TSS_annotated=\")[1].split(\")\")[0]\n",
    "                    \n",
    "                    #Get information to dict\n",
    "                    AUGUSTUS_testset_preds[\"species\"].append(species)\n",
    "                    AUGUSTUS_testset_preds[\"seq_type\"].append(seq_type)\n",
    "                    AUGUSTUS_testset_preds[\"label\"].append(float(label))\n",
    "                    AUGUSTUS_testset_preds[\"annotation_source\"].append(source)\n",
    "                    AUGUSTUS_testset_preds[\"seq_number\"].append(seq_number)\n",
    "                    AUGUSTUS_testset_preds[\"dataset_type\"].append(\"testset\")\n",
    "                    AUGUSTUS_testset_preds[\"first_downstream_intron\"].append(None)\n",
    "                    AUGUSTUS_testset_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "                    AUGUSTUS_testset_preds[\"5_flanking_sequence_missing\"].append(None)\n",
    "                    AUGUSTUS_testset_preds[\"3_flanking_sequence_missing\"].append(None)\n",
    "                \n",
    "                    #Find labelled ATG position in sequence\n",
    "                    match_atg = re.search(r'ATG_pos=(\\d+)', line)\n",
    "                    if match_atg:\n",
    "                        atg_pos_value = int(match_atg.group(1))\n",
    "                        atg_pos = atg_pos_value + 1\n",
    "                    \n",
    "                    predicted_atg_pos_list = []\n",
    "                    initiated = True\n",
    "                \n",
    "                #Get all start codon annotations\n",
    "                if \"start_codon\" in line:\n",
    "                    predicted_atg_pos_list.append(int(line.split(\"start_codon\\t\")[1].split(\"\\t\")[0]))\n",
    "            \n",
    "            #Last sequence\n",
    "            #If the matching start codon is found; TIS predicted\n",
    "            if atg_pos in predicted_atg_pos_list:\n",
    "                AUGUSTUS_testset_preds[\"preds\"].append(1.0)\n",
    "            #If the matching start codon is not found; TIS not predicted\n",
    "            else:\n",
    "                AUGUSTUS_testset_preds[\"preds\"].append(0.0)\n",
    "\n",
    "        \n",
    "        #Repeat for genomic test set\n",
    "        initiated = False\n",
    "        with open(f'../../data/data_evaluation/AUGUSTUS/preds/{dir}/genomic/{species}_preds.gff', \"r\") as file:\n",
    "            for line in file:\n",
    "                if line.startswith(\"# ----- prediction on sequence number\"):\n",
    "                    \n",
    "                    if initiated == True:\n",
    "                        \n",
    "                        #If the matching start codon is found; TIS predicted\n",
    "                        if atg_pos in predicted_atg_pos_list:\n",
    "                            AUGUSTUS_genomic_preds[\"preds\"].append(1.0)\n",
    "                        #If the matching start codon is not found; TIS not predicted\n",
    "                        else:\n",
    "                            AUGUSTUS_genomic_preds[\"preds\"].append(0.0)\n",
    "                    \n",
    "                    gene_name = line.split(\"name = \")[1].split(\"|\")[0]\n",
    "                    source = line.split(\"annotation_source=\")[1].split(\"|\")[0] \n",
    "                    first_downstream_intron = line.split(\"first_downstream_intron_start=\")[1].split(\"|\")[0] \n",
    "                    missing_5_flanking_seq = line.split(\"5_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "                    missing_3_flanking_seq = line.split(\"3_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "                    TSS_annotated = line.split(\"TSS_annotated=\")[1].split(\")\")[0].strip()\n",
    "                    \n",
    "                    #Get information to dict\n",
    "                    AUGUSTUS_genomic_preds[\"species\"].append(species)\n",
    "                    AUGUSTUS_genomic_preds[\"seq_type\"].append(\"Genomic TIS\")\n",
    "                    AUGUSTUS_genomic_preds[\"label\"].append(float(1))\n",
    "                    AUGUSTUS_genomic_preds[\"annotation_source\"].append(source)\n",
    "                    AUGUSTUS_genomic_preds[\"seq_number\"].append(gene_name)\n",
    "                    AUGUSTUS_genomic_preds[\"dataset_type\"].append(\"genomic\")\n",
    "                    AUGUSTUS_genomic_preds[\"first_downstream_intron\"].append(int(first_downstream_intron))\n",
    "                    AUGUSTUS_genomic_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "                    AUGUSTUS_genomic_preds[\"5_flanking_sequence_missing\"].append(missing_5_flanking_seq)\n",
    "                    AUGUSTUS_genomic_preds[\"3_flanking_sequence_missing\"].append(missing_3_flanking_seq)\n",
    "                    \n",
    "                    #Find labelled ATG position\n",
    "                    match_atg = re.search(r'TIS_position=(\\d+)', line)\n",
    "                    if match_atg:\n",
    "                        atg_pos_value = int(match_atg.group(1))\n",
    "                        atg_pos = atg_pos_value + 1\n",
    "                    \n",
    "                    predicted_atg_pos_list = []\n",
    "                    initiated = True\n",
    "                \n",
    "                #Get all start codon annotations\n",
    "                if \"start_codon\" in line:\n",
    "                    predicted_atg_pos_list.append(int(line.split(\"start_codon\\t\")[1].split(\"\\t\")[0]))\n",
    "                    ###If the matching start codon is found\n",
    "            \n",
    "            if atg_pos in predicted_atg_pos_list:\n",
    "                AUGUSTUS_genomic_preds[\"preds\"].append(1.0)\n",
    "            else:\n",
    "                AUGUSTUS_genomic_preds[\"preds\"].append(0.0)\n",
    "                \n",
    "    augustus_testset_df = pd.DataFrame(AUGUSTUS_testset_preds)\n",
    "    augustus_genomic_df = pd.DataFrame(AUGUSTUS_genomic_preds)\n",
    "\n",
    "    return augustus_testset_df, augustus_genomic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetStart 2.0 and ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netstart_preds(preds_subpath):\n",
    "   netstart_testset_preds = init_dict_testsets()\n",
    "   netstart_genomic_preds = init_dict_testsets()\n",
    "   \n",
    "   for species in tqdm(species_list, desc=f\"Processing {preds_subpath}\"):\n",
    "       #Process testset\n",
    "       try:\n",
    "           df = pd.read_csv(f\"../../data/data_evaluation/{preds_subpath}/testset/preds_{species}.csv.gz\", compression = \"gzip\")\n",
    "           \n",
    "           #Extract all fields using vectorized operations\n",
    "           df['seq_number'] = df['entry_line'].str.extract(r'seq_number=([^|]+)')\n",
    "           df['seq_type'] = df['entry_line'].str.extract(r'type=([^|]+)') \n",
    "           df['label'] = df['entry_line'].str.extract(r'TIS=([^|]+)').astype(float)\n",
    "           df['source'] = df['entry_line'].str.extract(r'source=([^|]+)')\n",
    "           df['TSS_annotated'] = df['entry_line'].str.extract(r'TSS_annotated=(.+)$')\n",
    "           df['ATG_pos'] = df['entry_line'].str.extract(r'ATG_pos=(\\d+)').astype(int)\n",
    "           \n",
    "           #Filter matches and append in bulk\n",
    "           matches = df[df['ATG_pos'] == df['atg_position']]\n",
    "           \n",
    "           if not matches.empty:\n",
    "               netstart_testset_preds['species'].extend([species] * len(matches))\n",
    "               netstart_testset_preds['seq_type'].extend(matches['seq_type'])\n",
    "               netstart_testset_preds['label'].extend(matches['label'])\n",
    "               netstart_testset_preds['preds'].extend(matches['preds'].astype(float))\n",
    "               netstart_testset_preds['annotation_source'].extend(matches['source'])\n",
    "               netstart_testset_preds['seq_number'].extend(matches['seq_number'])\n",
    "               netstart_testset_preds['dataset_type'].extend(['testset'] * len(matches))\n",
    "               netstart_testset_preds['first_downstream_intron'].extend([None] * len(matches))\n",
    "               netstart_testset_preds['TSS_annotated'].extend(matches['TSS_annotated'])\n",
    "               netstart_testset_preds['5_flanking_sequence_missing'].extend([None] * len(matches))\n",
    "               netstart_testset_preds['3_flanking_sequence_missing'].extend([None] * len(matches))\n",
    "       except FileNotFoundError:\n",
    "           continue\n",
    "\n",
    "\n",
    "       #Process genomic set \n",
    "       try:\n",
    "           df = pd.read_csv(f\"../../data/data_evaluation/{preds_subpath}/genomic/preds_{species}.csv.gz\", compression = \"gzip\")\n",
    "\n",
    "           df['gene_name'] = df['entry_line'].str.extract(r'([^|]+)')\n",
    "           df['source'] = df['entry_line'].str.extract(r'source=([^|]+)')\n",
    "           df['first_downstream_intron'] = df['entry_line'].str.extract(r'first_downstream_intron_start=([^|]+)').astype(int)\n",
    "           df['missing_5_flanking_seq'] = df['entry_line'].str.extract(r'5_flanking_sequence_missing=([^|]+)')\n",
    "           df['missing_3_flanking_seq'] = df['entry_line'].str.extract(r'3_flanking_sequence_missing=([^|]+)')\n",
    "           df['TSS_annotated'] = df['entry_line'].str.extract(r'TSS_annotated=(.+)$')\n",
    "           df['ATG_pos'] = df['entry_line'].str.extract(r'TIS_position=(\\d+)').astype(int)\n",
    "           \n",
    "           matches = df[df['ATG_pos'] == df['atg_position']]\n",
    "           \n",
    "           if not matches.empty:\n",
    "               netstart_genomic_preds['species'].extend([species] * len(matches))\n",
    "               netstart_genomic_preds['seq_type'].extend(['Genomic TIS'] * len(matches))\n",
    "               netstart_genomic_preds['label'].extend([1.0] * len(matches))\n",
    "               netstart_genomic_preds['preds'].extend(matches['preds'].astype(float))\n",
    "               netstart_genomic_preds['annotation_source'].extend(matches['source'])\n",
    "               netstart_genomic_preds['seq_number'].extend(matches['gene_name'])\n",
    "               netstart_genomic_preds['dataset_type'].extend(['testset'] * len(matches))\n",
    "               netstart_genomic_preds['first_downstream_intron'].extend(matches['first_downstream_intron'])\n",
    "               netstart_genomic_preds['TSS_annotated'].extend(matches['TSS_annotated'])\n",
    "               netstart_genomic_preds['5_flanking_sequence_missing'].extend(matches['missing_5_flanking_seq'])\n",
    "               netstart_genomic_preds['3_flanking_sequence_missing'].extend(matches['missing_3_flanking_seq'])\n",
    "       except FileNotFoundError:\n",
    "           continue\n",
    "           \n",
    "   return pd.DataFrame(netstart_testset_preds), pd.DataFrame(netstart_genomic_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiberius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiberius_preds(softmask):\n",
    "    #Initialize\n",
    "    tiberius_testset_preds = init_dict_testsets()\n",
    "    tiberius_genomic_preds = init_dict_testsets()\n",
    "\n",
    "    if softmask == True:\n",
    "        dir = \"softmask\"\n",
    "    else: \n",
    "        dir = \"no_softmask\"\n",
    "\n",
    "    #get predictions from all species\n",
    "    for species in species_list:\n",
    "\n",
    "        try:\n",
    "            seq_numbers = []\n",
    "\n",
    "            with open(f'../../data/data_evaluation/Tiberius/preds/{dir}/testset/testset_preds_{species}.gtf', \"r\") as file:\n",
    "\n",
    "                seq_pred_info_dict = dict()\n",
    "                for line in file:\n",
    "                    seq_number = line.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "                    seq_numbers.append(seq_number)\n",
    "                    entry_line = line.split(\"\\t\")[0]\n",
    "                    \n",
    "                    if entry_line not in seq_pred_info_dict:\n",
    "                        seq_pred_info_dict[entry_line] = []\n",
    "                    \n",
    "                    if line.split(\"\\t\")[2] == \"CDS\" in line:\n",
    "                        if \"cds_type=single\" in line or \"cds_type=initial\" in line:\n",
    "                            seq_pred_info_dict[entry_line].append(int(line.split(\"\\t\")[3])-1)\n",
    "\n",
    "\n",
    "            for entry_line in seq_pred_info_dict.keys():\n",
    "\n",
    "                seq_type = entry_line.split(\"type=\")[1].split(\"|\")[0].replace(\"_\", \" \")\n",
    "                label = entry_line.split(\"TIS=\")[1].split(\"|\")[0]\n",
    "                source = entry_line.split(\"source=\")[1].split(\"|\")[0] \n",
    "                atg_pos = int(entry_line.split(\"ATG_pos=\")[1].split(\"|\")[0])\n",
    "                TSS_annotated = entry_line.split(\"TSS_annotated=\")[1].split(\"|\")[0]\n",
    "                seq_number = entry_line.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "                \n",
    "                if atg_pos in seq_pred_info_dict[entry_line]:\n",
    "                    pred = 1.0\n",
    "                else:\n",
    "                    pred = 0.0\n",
    "\n",
    "                #Get information to dict\n",
    "                tiberius_testset_preds[\"species\"].append(species)\n",
    "                tiberius_testset_preds[\"seq_type\"].append(seq_type)\n",
    "                tiberius_testset_preds[\"label\"].append(float(label))\n",
    "                tiberius_testset_preds[\"preds\"].append(pred)\n",
    "                tiberius_testset_preds[\"annotation_source\"].append(source)\n",
    "                tiberius_testset_preds[\"seq_number\"].append(seq_number)\n",
    "                tiberius_testset_preds[\"dataset_type\"].append(\"testset\")\n",
    "                tiberius_testset_preds[\"first_downstream_intron\"].append(None)\n",
    "                tiberius_testset_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "                tiberius_testset_preds[\"5_flanking_sequence_missing\"].append(None)\n",
    "                tiberius_testset_preds[\"3_flanking_sequence_missing\"].append(None)\n",
    "\n",
    "            #Get a list of all test sequences\n",
    "            with gzip.open(f'../../data/data_evaluation/input_testsets/mRNA_testsets_processed/input_testset_{species}_softmasked.fasta.gz', \"rt\") as file:\n",
    "                for line in file:\n",
    "                    if line.startswith(\">\"):\n",
    "                        seq_number_testset = line.split(\"seq_number=\")[1].split(\"|\")[0]\n",
    "                        if seq_number_testset not in seq_numbers:\n",
    "                            #Get information to dict\n",
    "                            tiberius_testset_preds[\"species\"].append(species)\n",
    "                            tiberius_testset_preds[\"seq_type\"].append(line.split(\"type=\")[1].split(\"|\")[0])\n",
    "                            tiberius_testset_preds[\"preds\"].append(0.0)\n",
    "                            tiberius_testset_preds[\"annotation_source\"].append(line.split(\"source=\")[1].split(\"|\")[0])\n",
    "                            tiberius_testset_preds[\"seq_number\"].append(line.split(\"seq_number=\")[1].split(\"|\")[0])\n",
    "                            tiberius_testset_preds[\"dataset_type\"].append(\"testset\")\n",
    "                            tiberius_testset_preds[\"first_downstream_intron\"].append(None)\n",
    "                            tiberius_testset_preds[\"TSS_annotated\"].append(line.split(\"TSS_annotated=\")[1].split(\"|\")[0])\n",
    "                            tiberius_testset_preds[\"5_flanking_sequence_missing\"].append(None)\n",
    "                            tiberius_testset_preds[\"3_flanking_sequence_missing\"].append(None)\n",
    "                \n",
    "                            if seq_number_testset.startswith(\"TIS\"):\n",
    "                                tiberius_testset_preds[\"label\"].append(float(1.0))\n",
    "                            else:\n",
    "                                tiberius_testset_preds[\"label\"].append(float(0.0))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        \n",
    "        #Genomic test set\n",
    "        try:\n",
    "            gene_names = []\n",
    "\n",
    "            with open(f'../../data/data_evaluation/Tiberius/preds/{dir}/genomic/genomic_preds_{species}.gtf', \"r\") as file:\n",
    "\n",
    "                seq_pred_info_dict = dict()\n",
    "                for line in file:\n",
    "                    gene_name = line.split(\"|\")[1].split(\"|\")[0]\n",
    "                    gene_names.append(gene_name)\n",
    "                    entry_line = line.split(\"\\t\")[0]\n",
    "                    \n",
    "                    if entry_line not in seq_pred_info_dict:\n",
    "                        seq_pred_info_dict[entry_line] = []\n",
    "                    \n",
    "                    if line.split(\"\\t\")[2] == \"CDS\" in line:\n",
    "                        if \"cds_type=single\" in line or \"cds_type=initial\" in line:\n",
    "                            seq_pred_info_dict[entry_line].append(int(line.split(\"\\t\")[3])-1)\n",
    "\n",
    "            for entry_line in seq_pred_info_dict.keys():\n",
    "                gene_name = entry_line.split(\"|\")[1] \n",
    "                source = entry_line.split(\"source=\")[1].split(\"|\")[0] \n",
    "                atg_pos = int(entry_line.split(\"TIS_position=\")[1].split(\"|\")[0])\n",
    "                TSS_annotated = entry_line.split(\"TSS_annotated=\")[1].split(\"|\")[0].strip()\n",
    "                first_downstream_intron = entry_line.split(\"first_downstream_intron_start=\")[1].split(\"|\")[0]\n",
    "                missing_5_flanking_seq = entry_line.split(\"5_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "                missing_3_flanking_seq = entry_line.split(\"3_flanking_sequence_missing=\")[1].split(\"|\")[0]\n",
    "                \n",
    "                if atg_pos in seq_pred_info_dict[entry_line]:\n",
    "                    pred = 1.0\n",
    "                else:\n",
    "                    pred = 0.0\n",
    "\n",
    "                #Get information to dict\n",
    "                tiberius_genomic_preds[\"species\"].append(species)\n",
    "                tiberius_genomic_preds[\"seq_type\"].append(\"Genomic TIS\")\n",
    "                tiberius_genomic_preds[\"label\"].append(float(1.0))\n",
    "                tiberius_genomic_preds[\"preds\"].append(pred)\n",
    "                tiberius_genomic_preds[\"annotation_source\"].append(source)\n",
    "                tiberius_genomic_preds[\"seq_number\"].append(gene_name)\n",
    "                tiberius_genomic_preds[\"dataset_type\"].append(\"genomic\")\n",
    "                tiberius_genomic_preds[\"first_downstream_intron\"].append(first_downstream_intron)\n",
    "                tiberius_genomic_preds[\"TSS_annotated\"].append(TSS_annotated)\n",
    "                tiberius_genomic_preds[\"5_flanking_sequence_missing\"].append(missing_5_flanking_seq)\n",
    "                tiberius_genomic_preds[\"3_flanking_sequence_missing\"].append(missing_3_flanking_seq)\n",
    "\n",
    "\n",
    "            with gzip.open(f'../../data/data_evaluation/input_testsets/genomic_testsets/genes_extended_1000bp/genomic_testset_{species}.fasta.gz', \"rt\") as file:\n",
    "                for line in file:\n",
    "                    if line.startswith(\">\"):\n",
    "                        gene_name = line.split(\">\")[1].split(\"|\")[0]\n",
    "                        if gene_name not in gene_names:\n",
    "                            #Get information to dict\n",
    "                            tiberius_genomic_preds[\"species\"].append(species)\n",
    "                            tiberius_genomic_preds[\"seq_type\"].append(\"Genomic TIS\")\n",
    "                            tiberius_genomic_preds[\"label\"].append(float(1.0))\n",
    "                            tiberius_genomic_preds[\"preds\"].append(0.0)\n",
    "                            tiberius_genomic_preds[\"annotation_source\"].append(line.split(\"source=\")[1].split(\"|\")[0])\n",
    "                            tiberius_genomic_preds[\"seq_number\"].append(gene_name)\n",
    "                            tiberius_genomic_preds[\"dataset_type\"].append(\"genomic\")\n",
    "                            tiberius_genomic_preds[\"first_downstream_intron\"].append(line.split(\"first_downstream_intron_start=\")[1].split(\"|\")[0])\n",
    "                            tiberius_genomic_preds[\"TSS_annotated\"].append(line.split(\"TSS_annotated=\")[1].split(\"|\")[0].strip())\n",
    "                            tiberius_genomic_preds[\"5_flanking_sequence_missing\"].append(line.split(\"5_flanking_sequence_missing=\")[1].split(\"|\")[0])\n",
    "                            tiberius_genomic_preds[\"3_flanking_sequence_missing\"].append(line.split(\"3_flanking_sequence_missing=\")[1].split(\"|\")[0])\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "                \n",
    "    tiberius_df = pd.DataFrame(tiberius_testset_preds)\n",
    "    tiberius_genomic_df = pd.DataFrame(tiberius_genomic_preds)\n",
    "\n",
    "    return tiberius_df, tiberius_genomic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting NetStart 1.0-ish predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ablations/netstart1: 100%|██████████| 60/60 [29:48<00:00, 29.80s/it] \n"
     ]
    }
   ],
   "source": [
    "print(\"Getting TIS Transformer predictions\")\n",
    "TIS_transformer_df, TIS_transformer_genomic_df = get_tis_transformer_preds()\n",
    "#Save processed predictions\n",
    "TIS_transformer_df.to_csv('../../data/data_evaluation/preds_processed/testset/TIS_transformer_df.csv.gz', index=False, compression = \"gzip\")\n",
    "TIS_transformer_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/TIS_transformer_genomic_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "print(\"Getting AUGUSTUS predictions\")\n",
    "augustus_df, augustus_genomic_df = get_augustus_preds(softmask = True)\n",
    "augustus_no_softmask_df, augustus_genomic_no_softmask_df = get_augustus_preds(softmask = False)\n",
    "augustus_df.to_csv('../../data/data_evaluation/preds_processed/testset/augustus_df.csv.gz', index=False, compression = \"gzip\")#\n",
    "augustus_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/augustus_genomic_df.csv.gz', index=False, compression = \"gzip\")\n",
    "augustus_no_softmask_df.to_csv('../../data/data_evaluation/preds_processed/testset/augustus_no_softmask_df.csv.gz', index=False, compression = \"gzip\")\n",
    "augustus_genomic_no_softmask_df.to_csv('../../data/data_evaluation/preds_processed/genes/augustus_genomic_no_softmask_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "print(\"Getting NetStart 2.0 predictions\")\n",
    "netstart_overall_df, netstart_genomic_overall_df = get_netstart_preds(preds_subpath = \"netstart2.0/preds/overall\")\n",
    "netstart_overall_df.to_csv('../../data/data_evaluation/preds_processed/testset/netstart_overall_df.csv.gz', index=False, compression = \"gzip\")\n",
    "netstart_genomic_overall_df.to_csv('../../data/data_evaluation/preds_processed/genes/netstart_genomic_overall_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "netstart_group_df, netstart_genomic_group_df = get_netstart_preds(preds_subpath = \"netstart2.0/preds/group_specific\")\n",
    "netstart_group_df.to_csv('../../data/data_evaluation/preds_processed/testset/netstart_group_df.csv.gz', index=False, compression = \"gzip\")\n",
    "netstart_genomic_group_df.to_csv('../../data/data_evaluation/preds_processed/genes/netstart_genomic_group_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "print(\"Getting Tiberius predictions\")\n",
    "tiberius_df, tiberius_genomic_df = get_tiberius_preds(softmask = True)\n",
    "tiberius_no_softmask_df, tiberius_no_softmask_genomic_df = get_tiberius_preds(softmask = False)\n",
    "\n",
    "tiberius_df.to_csv('../../data/data_evaluation/preds_processed/testset/tiberius_df.csv.gz', index=False, compression = \"gzip\")\n",
    "tiberius_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/tiberius_genomic_df.csv.gz', index=False, compression = \"gzip\")\n",
    "tiberius_no_softmask_df.to_csv('../../data/data_evaluation/preds_processed/testset/tiberius_no_softmask_df.csv.gz', index=False, compression = \"gzip\")\n",
    "tiberius_no_softmask_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/tiberius_no_softmask_genomic_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "print(\"Getting NetStart 2.0A predictions\")\n",
    "esm2_finetuned_df, esm2_finetuned_genomic_df = get_netstart_preds(preds_subpath = \"ablations/esm2_finetuned\")\n",
    "esm2_finetuned_df.to_csv('../../data/data_evaluation/preds_processed/testset/esm2_finetuned_df.csv.gz', index=False, compression = \"gzip\")\n",
    "esm2_finetuned_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/esm2_finetuned_genomic_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "print(\"Getting NetStart 1.0A predictions\")\n",
    "netstart1_df, netstart1_genomic_df = get_netstart_preds(preds_subpath = \"ablations/netstart1\")\n",
    "#netstart1_df.to_csv('../../data/data_evaluation/preds_processed/testset/netstart1_df.csv.gz', index=False, compression = \"gzip\")\n",
    "netstart1_genomic_df.to_csv('../../data/data_evaluation/preds_processed/genes/netstart1_genomic_df.csv.gz', index=False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions with shuffled species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netstart_preds_species_shuffled(preds_subpath):\n",
    "   netstart_testset_preds = init_dict_testsets()\n",
    "   \n",
    "   for species in tqdm(species_list, desc=f\"Processing {preds_subpath}\"):\n",
    "       #Process testset\n",
    "       try:\n",
    "           df = pd.read_csv(f\"../../data/data_evaluation/{preds_subpath}/preds_{species}.csv.gz\", compression = \"gzip\")\n",
    "           \n",
    "           # Extract all fields using vectorized operations\n",
    "           df['seq_number'] = df['entry_line'].str.extract(r'seq_number=([^|]+)')\n",
    "           df['seq_type'] = df['entry_line'].str.extract(r'type=([^|]+)') \n",
    "           df['label'] = df['entry_line'].str.extract(r'TIS=([^|]+)').astype(float)\n",
    "           df['source'] = df['entry_line'].str.extract(r'source=([^|]+)')\n",
    "           df['TSS_annotated'] = df['entry_line'].str.extract(r'TSS_annotated=(.+)$')\n",
    "           df['ATG_pos'] = df['entry_line'].str.extract(r'ATG_pos=(\\d+)').astype(int)\n",
    "           \n",
    "           #Filter matches and append in bulk\n",
    "           matches = df[df['ATG_pos'] == df['atg_position']]\n",
    "           \n",
    "           if not matches.empty:\n",
    "               netstart_testset_preds['species'].extend([species] * len(matches))\n",
    "               netstart_testset_preds['seq_type'].extend(matches['seq_type'])\n",
    "               netstart_testset_preds['label'].extend(matches['label'])\n",
    "               netstart_testset_preds['preds'].extend(matches['preds'].astype(float))\n",
    "               netstart_testset_preds['annotation_source'].extend(matches['source'])\n",
    "               netstart_testset_preds['seq_number'].extend(matches['seq_number'])\n",
    "               netstart_testset_preds['dataset_type'].extend(['testset'] * len(matches))\n",
    "               netstart_testset_preds['first_downstream_intron'].extend([None] * len(matches))\n",
    "               netstart_testset_preds['TSS_annotated'].extend(matches['TSS_annotated'])\n",
    "               netstart_testset_preds['5_flanking_sequence_missing'].extend([None] * len(matches))\n",
    "               netstart_testset_preds['3_flanking_sequence_missing'].extend([None] * len(matches))\n",
    "       except FileNotFoundError:\n",
    "           continue\n",
    "           \n",
    "   return pd.DataFrame(netstart_testset_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing netstart2.0/preds/overall/testset_species_phylum_level: 100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get processed predictions with species label shuffled within overall systematic group\n",
    "#netstart_species_unknown_df = get_netstart_preds_species_shuffled(preds_subpath = \"netstart2.0/preds/overall/testset_species_unknown\")\n",
    "#netstart_species_unknown_df.to_csv('../../data/data_evaluation/preds_processed/testset/netstart_species_unknown_df.csv.gz', index=False, compression = \"gzip\")\n",
    "\n",
    "#Get processed predictions with species label shuffled within overall systematic group\n",
    "#netstart_phylum_df = get_netstart_preds_species_shuffled(preds_subpath = \"netstart2.0/preds/overall/testset_species_phylum_level\")\n",
    "#netstart_phylum_df.to_csv('../../data/data_evaluation/preds_processed/testset/netstart_phylum_level_df.csv.gz', index=False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
